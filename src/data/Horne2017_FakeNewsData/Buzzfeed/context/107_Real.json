{"foreign_id": "107_Real", "article1": {"title": "Facebook to Change News Feed to Focus on Friends and Family", "content": "SAN FRANCISCO \u2014 For years, Facebook has courted publishers of all sizes, asking them to depend more and more on the social media giant to expand their audiences. Now, Facebook has a new message for publishers: Tamp down your expectations.\n\nFacebook said on Wednesday that it planned to make a series of changes to its news feed algorithm so that it will more favorably promote content posted by the friends and family of users.\n\nThe side effect of those changes, the company said, is that content posted by publishers will show up less prominently in news feeds, resulting in significantly less traffic to the hundreds of news media sites that have come to rely on Facebook.\n\nThe move underscores the never-ending algorithm-tweaking that Facebook undertakes to maintain interest in its news feed, the company\u2019s marquee feature that is seen by more than 1.65 billion users every month.", "url": "https://www.nytimes.com/2016/06/30/technology/facebook-to-change-news-feed-to-focus-on-friends-and-family.html"}, "article2": {"title": "A timeline of Facebook's privacy issues \u2014 and its responses", "content": "SAN FRANCISCO \u2014 Facebook\u2019s recent crisis is just one of many privacy issues that company has had to deal with in its relatively short existence.\n\nBarely two years old in 2006, the company faced user outrage when it introduced its News Feed. A year later it had to apologize for telling people what their friends had bought. Years after that, the Federal Trade Commission stepped in \u2014 and is now looking at the company again. Facebook has a history of running afoul of regulators and weathering user anger, all the while collecting record profits and racking up more than 2 billion users.\n\nThose privacy issues are now front and center. Facebook's loose handling of how its data was acquired by app developers has plunged the company into the biggest crisis of its 14-year existence. The revelation that a data analytics company used by Donald Trump\u2019s presidential campaign was able to surreptitiously collect data on 50 million people through a seemingly innocuous quiz app has forced CEO Mark Zuckerberg to issue a public apology \u2014 and promise changes.\n\nTaking a step back to look at Facebook\u2019s pattern of privacy issues provides an important perspective on just how many times the company has faced serious criticism. What follows is a rundown of the biggest privacy issues Facebook has faced to date:\n\nWhen: September 2006\n\nWhat: Facebook debuts News Feed\n\nFacebook\u2019s response: Tells users to relax\n\nFacebook was only two years old when it introduced News Feed on Sept. 5, 2006. The curated feed was intended as a central destination so users didn't have to browse through friends' profiles to see what they had changed.\n\nFacebook had about 8 million users at the time, and not all of them were happy about every move of their personal life being blasted into a daily feed for their friends.\n\nAn estimated 1 million users joined \"Facebook News Feed protest groups,\" arguing the feature was too intrusive. But Facebook stayed the course.\n\n\u201cOne of the things I'm most proud of about Facebook is that we believe things can always be better, and we're willing to make big bets if we think it will help our community over the long term,\u201d Zuckerberg said in a post reflecting on the 10th anniversary of News Feed.\n\nThe outrage died down, and News Feed became a major part of Facebook\u2019s success.\n\nWhen: December 2007\n\nWhat: Beacon, Facebook\u2019s first big brush with advertising privacy issues\n\nFacebook\u2019s response: Zuckerberg apologizes, gives users choice to opt out\n\nThere was once a time when companies could track purchases by Facebook users and then notify their Facebook friends of what had been bought -- many times without any user consent.\n\nFacebook creator Mark Zuckerberg poses at Harvard University on May 14, 2004. Rick Friedman / Corbis via Getty Images\n\nIn an apology on Dec. 6, 2007, Zuckerberg explained his thought process behind the program, called Beacon, and announced that users would be given the option to opt out of it.\n\n\u201cWe were excited about Beacon because we believe a lot of information people want to share isn\u2019t on Facebook, and if we found the right balance, Beacon would give people an easy and controlled way to share more of that information with their friends,\u201d he said.\n\nAt the time, Facebook was also talking to the Federal Trade Commission (FTC) about online privacy and advertising.\n\nWhen: November 2011\n\nWhat: Facebook settles FTC privacy charges\n\nFacebook\u2019s response: Facebook agrees to undergo an independent privacy evaluation every other year for the next 20 years.\n\nFacebook settled with the Federal Trade Commission in 2011 over charges that it didn't keep its privacy promise to users by allowing private information to be made public without warning.\n\nRegulators said Facebook falsely claimed that third-party apps were able to access only the data they needed to operate. In fact, the apps could access nearly all of a user\u2019s personal data. Facebook users that never authenticated a third-party app could even have private posts collected if their friends used apps. Facebook was also charged with sharing user information with advertisers, despite a promise they wouldn\u2019t.\n\n\"Facebook is obligated to keep the promises about privacy that it makes to its hundreds of millions of users,\" Jon Leibowitz, then chairman of the FTC, said at the time. \"Facebook's innovation does not have to come at the expense of consumer privacy. The FTC action will ensure it will not.\"\n\nAs part of the agreement in 2011, Facebook remains liable for a $16,000-per-day penalty for violating each count of the settlement.\n\nWhen: June 2013\n\nWhat: Facebook bug exposes private contact info\n\nFacebook\u2019s response: Facebook fixes bug, notifies people whose info may have been exposed.\n\nA bug exposed the email addresses and phone numbers of 6 million Facebook users to anyone who had some connection to the person or knew at least one piece of their contact information.\n\nThe bug was discovered by a White Hat hacker \u2014 someone who hacks with the intention of helping companies find bugs and build better security practices.\n\nWhen people joined Facebook and uploaded their contact lists, Facebook explained it would match that data to other people on Facebook in order to create friend recommendations.\n\n\u201cFor example, we don\u2019t want to recommend that people invite contacts to join Facebook if those contacts are already on Facebook; instead, we want to recommend that they invite those contacts to be their friends on Facebook,\u201d Facebook\u2019s team explained in a June 2013 message.\n\nThat information was \u201cinadvertently stored in association with people\u2019s contact information,\u201d Facebook said. That meant that when a Facebook user chose to download their information through Facebook\u2019s DYI tool, they were provided with a list of additional contact information for people they knew or with whom they may have had some association.\n\nFacebook said it pulled the tool offline and fixed it. The company also said it had notified regulators and pledged to tell affected users.\n\nWhen: July 2014\n\nWhat: Mood-manipulation experiment on thousands of Facebook users\n\nFacebook\u2019s response: Facebook data scientist apologizes\n\nFacebook's mood-manipulation experiment in 2014 included more than half a million randomly selected users. Facebook altered their news feeds to show more positive or negative posts. The purpose of the study was to show how emotions could spread on social media. The results were published in the Proceedings of the National Academy of Sciences, kicking off a firestorm of backlash over whether the study was ethical.\n\nAdam D.I. Kramer, the Facebook data scientist who led the experiment, ultimately posted an apology on Facebook. Four years later, the experiment no longer appears to be online.\n\n\u201cI can understand why some people have concerns about it, and my co-authors and I are very sorry for the way the paper described the research and any anxiety it caused,\u201d he wrote, according to The New York Times.\n\nWhen: April 2015\n\nWhat: Facebook cuts off apps from taking basically all the data they want\n\nFacebook\u2019s response: Please keep building apps\n\nIf Person A downloads an app, that app shouldn\u2019t be able to suck data from Person B just because they\u2019re friends, right? In 2014, Facebook cited privacy concerns and promised it would limit access to developers. But by the time the policy took effect the next year, Facebook had one big issue: It still couldn\u2019t keep track of how many developers were using previously downloaded data, according to current and former employees who spoke with The Wall Street Journal.\n\nChris Wylie, from Canada, who once worked for the UK-based political consulting firm Cambridge Analytica, gives a talk entitled \"The Most Important Whistleblower Since Snowden: The Mind Behind Cambridge Analytica\" at the Frontline Club in London on March 20, 2018. Matt Dunham / AP\n\nWhen Paul Grewal, Facebook vice president and deputy general counsel announced Cambridge Analytica\u2019s ban from Facebook last week, he said Facebook has a policy of doing ongoing manual and automated checks to ensure apps are complying with Facebook policies.\n\n\u201cThese include steps such as random audits of existing apps along with the regular and proactive monitoring of the fastest growing apps,\u201d he said.\n\nWhen: January 2018\n\nWhat: Europe\u2019s data protection law\n\nFacebook\u2019s response: Facebook complies\n\nFacebook has also began preparing for the start of a strict European data protection law that takes effect in May. Called the General Data Protection Regulation, the law governs how companies store user information and requires them to disclose a breach within 72 hours.\n\nIn January, Facebook released a set of privacy principles explaining how users can take more control of their data.\n\nOne particularly notable principle many will be watching to see if Facebook upholds is accountability.\n\n\"In addition to comprehensive privacy reviews, we put products through rigorous data security testing. We also meet with regulators, legislators and privacy experts around the world to get input on our data practices and policies,\" Facebook's team said in January.\n\nWhen: February 2018\n\nWhat: Belgian court tells Facebook to stop tracking people across the entire internet\n\nFacebook\u2019s response: Appeal the court\u2019s ruling\n\nIn February, Facebook was ordered to stop collecting private information about Belgian users on third-party sites through the use of cookies. Facebook was also ordered to delete all data it collected illegally from Belgians, including those who aren't Facebook users but may have still landed on a Facebook page, or risk being fined up to 100 million euros.\n\nFacebook said it has complied with European data protection laws and gives people the choice to opt out of data collection on third-party websites and applications. The company said it would appeal the ruling.\n\nWhen: March 2018\n\nWhat: Revealed that Facebook knew about massive data theft and did nothing\n\nFacebook\u2019s response: An apology tour and policy changes\n\nThe world finally got the answer to the question \u201cWhere\u2019s Zuck?\u201d on Wednesday when the Facebook CEO and co-founder broke his silence on the data harvesting allegations. In a statement posted on his Facebook wall, Zuckerberg avoided the word \u201csorry\u201d but did express partial blame for Facebook\u2019s role in not doing enough to protect user privacy.\n\nFacebook Founder and CEO Mark Zuckerberg speaks at the annual Facebook developers conference in San Jose, California, in 2017. Stephen Lam / Reuters file\n\nHe laid out three steps Facebook will take now, including investigating all apps that were able to access user data before 2014, when the company began changing its permissions for developers. Facebook will put restrictions on the data apps can access, limiting them to a person\u2019s name, photo and email. Finally, Zuckerberg said Facebook will make an easy tool that lets everyone see which apps have access to their data and allow them to revoke access.\n\n\"I've been working to understand exactly what happened and how to make sure this doesn't happen again,\u201d he wrote. \u201cThe good news is that the most important actions to prevent this from happening again today we have already taken years ago. But we also made mistakes, there's more to do, and we need to step up and do it.\"", "url": "https://www.nbcnews.com/tech/social-media/timeline-facebook-s-privacy-issues-its-responses-n859651"}, "article3": {"title": "A new Facebook experiment \u201cpops\u201d your ideological bubble", "content": "In a divisive political age, research has shown that many Americans are blinded by their \u201cred\u201d and \u201cblue\u201d social media bubbles\u2014leaving them unable to understand or relate to those they disagree with. There may be a fix for that.\n\nA new digital tool disrupts homogeneous news feeds by connecting US Facebook users to people outside their filter bubbles. \u201cPop Your Bubble\u201d was released today, and is funded by The KIND Foundation, the non-profit arm of the granola bar company, which works to foster kinder and more empathetic communities.\n\nThe app was motivated by research showing that, while over 60% of Americans get news from social media, only 5% of US adults see social media posts that greatly differ from their perspectives. That\u2019s according to a new poll conducted by Morning Consult (on behalf of the KIND Foundation).\n\nKIND\u2019s tool, accessible here, seeks to boost that statistic. It prompts you to \u201cfollow\u201d Facebook users who have been identified by an algorithm as your demographic opposite. The algorithm accounts for geographic location (urban vs. rural), age, hometown, and previously liked and shared content (the attributes are ranked in that order). It also balances results to ensure a gender mix. \u201cOur tool intentionally matches people on a basis broader than politics, to better account for the whole of who they are,\u201d says Elle Lanning, an advisor to The KIND Foundation.\n\nImportantly, \u201cfollowing\u201d is a one-way relationship: When you follow a match, you can see their public posts on your News Feed, but they can\u2019t see yours (unless they follow you back). Following a person doesn\u2019t make you Facebook \u201cfriends.\u201d KIND hopes the app facilitates dialogue, but doesn\u2019t push users to \u201clike,\u201d or comment on their matches\u2019 posts.\n\nOnce you\u2019ve followed ten new people via the app, you can choose to add your profile, allowing others to follow you. Your profile will not appear in the app unless you\u2019ve opted into the experiment, which hundreds already have.\n\nUnlike Facebook\u2019s effort to police users who post fake news, \u201cPop Your Bubble\u201d bets on humanity\u2019s better side\u2014our drive to understand, rather than vilify, the \u201copposition.\u201d This mission aligns naturally with KIND\u2019s values, according to Daniel Lubetzky, the company\u2019s founder and CEO.\n\nLubetzky, who describes himself as the son of a holocaust survivor and a father of four, says he cannot shake the immense division and alienation that\u2019s become increasingly evident since the 2016 US election. Lubetzky says that private corporations have a moral responsibility to tackle major issues, from climate change to drug threats to political divides, as government can\u2019t do it alone.\n\nThe \u201cPop Your Bubble\u201d app is the KIND Foundation\u2019s first digital community-building venture. \u201cWe need to understand the other side to impact the other side,\u201d says Lubetzky, \u201cWe become much more effective as humans and leaders when we engage in hearty conversations with those who are different from us, not necessarily to change our opinions, but to build the empathy muscle.\u201d\n\nFollowing different people on Facebook, of course, will not eliminate filter bubbles or resolve deep-rooted biases. But it\u2019s a first step\u2014a playful way to embrace the discomfort of the unfamiliar.\n\n\u201cWe\u2019ve approached the project with a lot of humility, and we have no idea what results will be,\u201d says Lubetzky. \u201cBut what would happen if your feed helped you at least think about opinions you disagree with, instead of just reinforcing your beliefs? We think that\u2019s a healthy question to ask.\u201d\n\nSign up for the Quartz Daily Brief, our free daily newsletter with the world\u2019s most important and interesting news.\n\nMore stories from Quartz:", "url": "https://finance.yahoo.com/news/facebook-experiment-pops-ideological-bubble-132819412.html"}}